# gpt-2
This is a fork of **nshepperd**'s [repo](https://github.com/nshepperd/gpt-2) for finetuning **OpenAi**'s language model [gpt-2](https://github.com/openai/gpt-2)

## Usage
This repository is intended to be used for finetuning gpt-2 on transcripts from the Joe Rogan Experience podcast. The retrained model is then used in my [Dialogue Modelling Transformer Network](https://github.com/clayajohnson/dialogue_modelling_transformer_network) project.

More details coming soon

## License
[MIT](./LICENSE)
